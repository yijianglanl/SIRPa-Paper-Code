{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9vKdScEHKBE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "from scipy.optimize import minimize, differential_evolution\n",
        "from scipy.stats import norm, chi2\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "from scipy.interpolate import interp1d\n",
        "import itertools\n",
        "\n",
        "# -----------------------------\n",
        "# ODE model\n",
        "# -----------------------------\n",
        "def ode_rhs(t, y, p):\n",
        "    a1, a2, a3, a4, a5, a6 = p\n",
        "    y1, y2 = y\n",
        "    dy1 = a1 * y1 * (1 - y1 / a2) - a3 * y1 * y2\n",
        "    dy2 = a4 - a5 * y2 - a6 * y1 * y2\n",
        "    return [dy1, dy2]\n",
        "\n",
        "def solve_dataset(t_obs, params, y10, y20, method=\"BDF\", rtol=1e-5, atol=1e-7):\n",
        "    sol = solve_ivp(lambda t, y: ode_rhs(t, y, params),\n",
        "                    (t_obs[0], t_obs[-1]), [y10, y20],\n",
        "                    t_eval=t_obs, method=method, rtol=rtol, atol=atol)\n",
        "    return sol.y[0] + sol.y[1]\n",
        "\n",
        "# -----------------------------\n",
        "# Experimental setup\n",
        "# -----------------------------\n",
        "t_obs = [\n",
        "    np.array([14, 16, 18, 20, 22, 24, 26, 28, 30], float),\n",
        "    np.array([12, 14, 16, 18, 20, 22, 24, 26], float),\n",
        "    np.array([ 6,  8, 10, 12, 14, 16, 18, 20], float),\n",
        "    np.array([ 2,  4,  6,  8, 10, 12, 14], float)\n",
        "]\n",
        "\n",
        "theta_true = np.array([\n",
        "    0.380159, 1.8637e+09, 1.40997e-08,\n",
        "    125102,   0.00308406, 3.33798e-09,\n",
        "    1.43323e+06,\n",
        "    9.38924e+06, 2.5943e+07, 2.48114e+07, 6.61559e+07\n",
        "])\n",
        "\n",
        "lb_kin = np.array([0.35, 1.6e9, 0.8e-8, 8e4, 1e-3, 1e-9], float)\n",
        "ub_kin = np.array([0.38, 2.2e9, 2.7e-8, 1.4e5, 1.8e-1, 5.5e-9], float)\n",
        "y1min, y1max = 1e3, 5e8\n",
        "y2min, y2max = 1e1, 1e7\n",
        "lb_all = np.concatenate([lb_kin, [y2min], [y1min]*4])\n",
        "ub_all = np.concatenate([ub_kin, [y2max], [y1max]*4])\n",
        "bounds_list = list(zip(lb_all, ub_all))\n",
        "\n",
        "# -----------------------------\n",
        "# Generate noisy data\n",
        "# -----------------------------\n",
        "CV, SigmaFloor = 0.025, 1e5\n",
        "exp_data, sigma_data = [], []\n",
        "params_true = theta_true[:6]\n",
        "y2_true = theta_true[6]\n",
        "y1_trues = theta_true[7:]\n",
        "\n",
        "for i, y10 in enumerate(y1_trues):\n",
        "    clean = solve_dataset(t_obs[i], params_true, y10, y2_true, \"BDF\")\n",
        "    sigma_vals = np.maximum(CV * clean, SigmaFloor)\n",
        "    noisy = clean + np.random.normal(0, sigma_vals)\n",
        "    exp_data.append(noisy)\n",
        "    sigma_data.append(sigma_vals)\n",
        "\n",
        "print(\"Synthetic noisy data generated.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Log-likelihood\n",
        "# -----------------------------\n",
        "def loglikelihood(theta, method=\"BDF\"):\n",
        "    a_params = theta[:6]\n",
        "    y20 = theta[6]\n",
        "    y10s = theta[7:]\n",
        "    ll_total = 0.0\n",
        "    for i in range(4):\n",
        "        pred = solve_dataset(t_obs[i], a_params, y10s[i], y20, method, rtol=1e-5, atol=1e-7)\n",
        "        resid = exp_data[i] - pred\n",
        "        sigmas = sigma_data[i]\n",
        "        ll_total += np.sum(norm.logpdf(resid, loc=0, scale=sigmas))\n",
        "    return ll_total\n",
        "\n",
        "def neg_ll(theta):\n",
        "    return -loglikelihood(theta, method=\"BDF\")\n",
        "\n",
        "# -----------------------------\n",
        "# Compute MLE with global + local search (faster settings)\n",
        "# -----------------------------\n",
        "print(\"Running global optimization...\")\n",
        "res_global = differential_evolution(neg_ll, bounds_list, maxiter=20, popsize=10, polish=False, workers=-1, tol=0.1)\n",
        "print(\"Global search done. Refining with local search...\")\n",
        "res_local = minimize(neg_ll, res_global.x, bounds=bounds_list,\n",
        "                     method=\"L-BFGS-B\", options={\"maxiter\":100, \"ftol\":1e-5})\n",
        "theta_mle = res_local.x\n",
        "print(\"Optimization success:\", res_local.success)\n",
        "print(\"MLE parameters:\", theta_mle)\n",
        "\n",
        "# -----------------------------\n",
        "# Profile likelihood with warm starts (only for kinetic parameters)\n",
        "# -----------------------------\n",
        "def profile_likelihood(param_index, theta_mle, bounds, method=\"BDF\", n_grid=15):\n",
        "    p_grid = np.linspace(bounds[param_index][0], bounds[param_index][1], n_grid)\n",
        "    ll_values = np.empty_like(p_grid)\n",
        "    ll_mle = loglikelihood(theta_mle, method)\n",
        "\n",
        "    nuisance_guess = [theta_mle[i] for i in range(len(theta_mle)) if i != param_index]\n",
        "\n",
        "    for j, val in enumerate(tqdm(p_grid, desc=f\"Param {param_index+1}\")):\n",
        "        theta_fixed = theta_mle.copy()\n",
        "        theta_fixed[param_index] = val\n",
        "        free_idx = [i for i in range(len(theta_mle)) if i != param_index]\n",
        "        free_bounds = [bounds[i] for i in free_idx]\n",
        "\n",
        "        def neg_ll_nuisance(free_params):\n",
        "            theta_var = theta_fixed.copy()\n",
        "            theta_var[free_idx] = free_params\n",
        "            return -loglikelihood(theta_var, method)\n",
        "\n",
        "        res = minimize(neg_ll_nuisance, nuisance_guess, bounds=free_bounds,\n",
        "                       method=\"L-BFGS-B\", options={\"ftol\":1e-5, \"gtol\":1e-5, \"maxiter\":50})\n",
        "        ll_values[j] = -res.fun\n",
        "        nuisance_guess = res.x\n",
        "\n",
        "    norm_ll = ll_values - ll_mle\n",
        "    return param_index, p_grid, norm_ll\n",
        "\n",
        "# -----------------------------\n",
        "# Run profiles only for kinetic parameters (first 6)\n",
        "# -----------------------------\n",
        "print(\"Running profile likelihood analysis for kinetic parameters...\")\n",
        "results = Parallel(n_jobs=4)(\n",
        "    delayed(profile_likelihood)(i, theta_mle, bounds_list, \"BDF\", n_grid=15)\n",
        "    for i in range(6)\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Extract 95% CIs for kinetic parameters\n",
        "# -----------------------------\n",
        "cutoff = -chi2.ppf(0.95, df=1)/2\n",
        "param_labels = [r\"$c_1$\", r\"$c_{max}$\", r\"$\\phi_e$\", r\"$\\gamma_e$\", r\"$\\delta_e$\", r\"$\\eta_e$\"]\n",
        "\n",
        "def extract_ci(p_grid, norm_ll, cutoff):\n",
        "    \"\"\"Interpolate CI from profile likelihood curve\"\"\"\n",
        "    try:\n",
        "        # Find where the profile crosses the cutoff\n",
        "        below = norm_ll < cutoff\n",
        "        if np.any(below):\n",
        "            # Get indices where it crosses\n",
        "            cross_idx = np.where(np.diff(below.astype(int)) != 0)[0]\n",
        "            if len(cross_idx) >= 2:\n",
        "                lower = np.interp(cutoff, norm_ll[cross_idx[0]:cross_idx[0]+2],\n",
        "                                 p_grid[cross_idx[0]:cross_idx[0]+2])\n",
        "                upper = np.interp(cutoff, norm_ll[cross_idx[1]:cross_idx[1]+2],\n",
        "                                 p_grid[cross_idx[1]:cross_idx[1]+2])\n",
        "                return lower, upper\n",
        "        return None, None\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "cis = {}\n",
        "for param_index, p_grid, norm_ll in results:\n",
        "    lower, upper = extract_ci(p_grid, norm_ll, cutoff)\n",
        "    cis[param_labels[param_index]] = (lower, upper)\n",
        "\n",
        "print(\"\\n95% Confidence Intervals (from profiles):\")\n",
        "for k,v in cis.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Parameter co-variability analysis (only for kinetic parameters)\n",
        "# -----------------------------\n",
        "def parameter_covariability(param_indices, theta_mle, bounds, method=\"BDF\", n_grid=8):\n",
        "    \"\"\"Analyze co-variability between two parameters\"\"\"\n",
        "    param1_idx, param2_idx = param_indices\n",
        "    p1_grid = np.linspace(bounds[param1_idx][0], bounds[param1_idx][1], n_grid)\n",
        "    p2_grid = np.linspace(bounds[param2_idx][0], bounds[param2_idx][1], n_grid)\n",
        "\n",
        "    # Create meshgrid for the two parameters\n",
        "    P1, P2 = np.meshgrid(p1_grid, p2_grid)\n",
        "    ll_values = np.zeros_like(P1)\n",
        "\n",
        "    ll_mle = loglikelihood(theta_mle, method)\n",
        "    cutoff = -chi2.ppf(0.95, df=2)/2  # For 2D confidence region\n",
        "\n",
        "    # For each point in the grid, optimize the remaining parameters\n",
        "    for i in tqdm(range(n_grid), desc=f\"Params {param1_idx+1}-{param2_idx+1}\"):\n",
        "        for j in range(n_grid):\n",
        "            theta_fixed = theta_mle.copy()\n",
        "            theta_fixed[param1_idx] = P1[i, j]\n",
        "            theta_fixed[param2_idx] = P2[i, j]\n",
        "\n",
        "            free_indices = [idx for idx in range(len(theta_mle))\n",
        "                          if idx not in [param1_idx, param2_idx]]\n",
        "            free_bounds = [bounds[idx] for idx in free_indices]\n",
        "\n",
        "            def neg_ll_nuisance(free_params):\n",
        "                theta_var = theta_fixed.copy()\n",
        "                theta_var[free_indices] = free_params\n",
        "                return -loglikelihood(theta_var, method)\n",
        "\n",
        "            # Use the MLE values as initial guess for nuisance parameters\n",
        "            nuisance_guess = theta_mle[free_indices]\n",
        "            res = minimize(neg_ll_nuisance, nuisance_guess, bounds=free_bounds,\n",
        "                          method=\"L-BFGS-B\", options={\"ftol\":1e-4, \"maxiter\":30})\n",
        "\n",
        "            ll_values[i, j] = -res.fun\n",
        "\n",
        "    norm_ll = ll_values - ll_mle\n",
        "    return param1_idx, param2_idx, P1, P2, norm_ll, cutoff\n",
        "\n",
        "# -----------------------------\n",
        "# Run co-variability analysis for parameter pairs (only kinetic parameters)\n",
        "# -----------------------------\n",
        "# Select which parameter pairs to analyze (first 6 parameters)\n",
        "param_pairs = list(itertools.combinations(range(6), 2))[:6]  # Only first 6 pairs to save time\n",
        "covariability_results = []\n",
        "\n",
        "print(\"Running parameter co-variability analysis for kinetic parameters...\")\n",
        "for param_pair in param_pairs:\n",
        "    result = parameter_covariability(param_pair, theta_mle, bounds_list, \"BDF\", n_grid=6)\n",
        "    covariability_results.append(result)\n",
        "    print(f\"Completed analysis for parameters {param_pair[0]+1} and {param_pair[1]+1}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot co-variability results\n",
        "# -----------------------------\n",
        "param_labels = [r\"$a_1$\", r\"$a_2$\", r\"$a_3$\", r\"$a_4$\", r\"$a_5$\", r\"$a_6$\"]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (param1_idx, param2_idx, P1, P2, norm_ll, cutoff) in enumerate(covariability_results):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Plot contour of the confidence region\n",
        "    contour = ax.contour(P1, P2, norm_ll, levels=[cutoff], colors='red', linewidths=2)\n",
        "    ax.clabel(contour, inline=True, fontsize=10)\n",
        "\n",
        "    # Add a heatmap for the log-likelihood surface\n",
        "    im = ax.contourf(P1, P2, norm_ll, levels=10, alpha=0.7, cmap='viridis')\n",
        "\n",
        "    # Mark the MLE point\n",
        "    ax.plot(theta_mle[param1_idx], theta_mle[param2_idx], 'ro', markersize=8)\n",
        "\n",
        "    ax.set_xlabel(param_labels[param1_idx])\n",
        "    ax.set_ylabel(param_labels[param2_idx])\n",
        "    ax.set_title(f\"{param_labels[param1_idx]} vs {param_labels[param2_idx]}\")\n",
        "\n",
        "    # Add colorbar\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Parameter Co-variability in 95% Confidence Region (Kinetic Parameters Only)\", fontsize=14)\n",
        "plt.subplots_adjust(top=0.93)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Extract parameter correlations\n",
        "# -----------------------------\n",
        "print(\"\\nParameter correlations from co-variability analysis:\")\n",
        "for param1_idx, param2_idx, P1, P2, norm_ll, cutoff in covariability_results:\n",
        "    # Find points within the confidence region\n",
        "    in_region = norm_ll >= cutoff\n",
        "\n",
        "    if np.any(in_region):\n",
        "        # Calculate correlation coefficient for points in confidence region\n",
        "        p1_values = P1[in_region]\n",
        "        p2_values = P2[in_region]\n",
        "        correlation = np.corrcoef(p1_values, p2_values)[0, 1]\n",
        "\n",
        "        print(f\"{param_labels[param1_idx]} & {param_labels[param2_idx]}: r = {correlation:.3f}\")\n",
        "\n",
        "        # Calculate parameter ranges within confidence region\n",
        "        p1_min, p1_max = np.min(p1_values), np.max(p1_values)\n",
        "        p2_min, p2_max = np.min(p2_values), np.max(p2_values)\n",
        "\n",
        "        print(f\"  {param_labels[param1_idx]} range in 95% CI: [{p1_min:.3g}, {p1_max:.3g}]\")\n",
        "        print(f\"  {param_labels[param2_idx]} range in 95% CI: [{p2_min:.3g}, {p2_max:.3g}]\")\n",
        "    else:\n",
        "        print(f\"{param_labels[param1_idx]} & {param_labels[param2_idx]}: No significant correlation\")\n",
        "\n",
        "print(\"\\nAnalysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_labels = [r\"$c_1$\", r\"$c_{max}$\", r\"$\\phi_{e}$\",r\"$\\gamma_e$\", r\"$\\delta_{e}$\", r\"$\\eta_{e}$\"]\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (param1_idx, param2_idx, P1, P2, norm_ll, cutoff) in enumerate(covariability_results):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Plot contour of the confidence region\n",
        "    contour = ax.contour(P1, P2, norm_ll, levels=[cutoff], colors='orange', linewidths=2)\n",
        "    ax.clabel(contour, inline=True, fontsize=10)\n",
        "\n",
        "    # Add a heatmap for the log-likelihood surface\n",
        "    im = ax.contourf(P1, P2, norm_ll, levels=10, alpha=0.7, cmap='Blues')\n",
        "\n",
        "    # Mark the MLE point\n",
        "    ax.plot(theta_mle[param1_idx], theta_mle[param2_idx], 'ro', markersize=8)\n",
        "\n",
        "    ax.set_xlabel(param_labels[param1_idx])\n",
        "    ax.set_ylabel(param_labels[param2_idx])\n",
        "    #ax.set_title(f\"{param_labels[param1_idx]} vs {param_labels[param2_idx]}\")\n",
        "\n",
        "    # Add colorbar\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Parameter Co-variability in 95% Confidence Region (Kinetic Parameters Only)\", fontsize=14)\n",
        "plt.subplots_adjust(top=0.93)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Extract parameter correlations\n",
        "# -----------------------------\n",
        "print(\"\\nParameter correlations from co-variability analysis:\")\n",
        "for param1_idx, param2_idx, Pæž, P2, norm_ll, cutoff in covariability_results:\n",
        "    # Find points within the confidence region\n",
        "    in_region = norm_ll >= cutoff\n",
        "\n",
        "    if np.any(in_region):\n",
        "        # Calculate correlation coefficient for points in confidence region\n",
        "        p1_values = P1[in_region]\n",
        "        p2_values = P2[in_region]\n",
        "        correlation = np.corrcoef(p1_values, p2_values)[0, 1]\n",
        "\n",
        "        print(f\"{param_labels[param1_idx]} & {param_labels[param2_idx]}: r = {correlation:.3f}\")\n",
        "\n",
        "        # Calculate parameter ranges within confidence region\n",
        "        p1_min, p1_max = np.min(p1_values), np.max(p1_values)\n",
        "        p2_min, p2_max = np.min(p2_values), np.max(p2_values)\n",
        "\n",
        "        print(f\"  {param_labels[param1_idx]} range in 95% CI: [{p1_min:.3g}, {p1_max:.3g}]\")\n",
        "        print(f\"  {param_labels[param2_idx]} range in 95% CI: [{p2_min:.3g}, {p2_max:.3g}]\")\n",
        "    else:\n",
        "        print(f\"{param_labels[param1_idx]} & {param_labels[param2_idx]}: No significant correlation\")\n",
        "\n",
        "print(\"\\nAnalysis complete!\")"
      ],
      "metadata": {
        "id": "sQ5X7J4jHaL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}