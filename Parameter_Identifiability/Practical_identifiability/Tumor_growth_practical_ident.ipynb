{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJp2WqVM51pd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "from scipy.optimize import minimize, differential_evolution\n",
        "from scipy.stats import norm, chi2\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# ODE model\n",
        "# -----------------------------\n",
        "def ode_rhs(t, y, p):\n",
        "    a1, a2, a3, a4, a5, a6 = p\n",
        "    y1, y2 = y\n",
        "    dy1 = a1 * y1 * (1 - y1 / a2) - a3 * y1 * y2\n",
        "    dy2 = a4 - a5 * y2 - a6 * y1 * y2\n",
        "    return [dy1, dy2]\n",
        "\n",
        "def solve_dataset(t_obs, params, y10, y20, method=\"BDF\", rtol=1e-5, atol=1e-7):\n",
        "    sol = solve_ivp(lambda t, y: ode_rhs(t, y, params),\n",
        "                    (t_obs[0], t_obs[-1]), [y10, y20],\n",
        "                    t_eval=t_obs, method=method, rtol=rtol, atol=atol)\n",
        "    return sol.y[0] + sol.y[1]\n",
        "\n",
        "# -----------------------------\n",
        "# Experimental setup\n",
        "# -----------------------------\n",
        "t_obs = [\n",
        "    np.array([14, 16, 18, 20, 22, 24, 26, 28, 30], float),\n",
        "    np.array([12, 14, 16, 18, 20, 22, 24, 26], float),\n",
        "    np.array([ 6,  8, 10, 12, 14, 16, 18, 20], float),\n",
        "    np.array([ 2,  4,  6,  8, 10, 12, 14], float)\n",
        "]\n",
        "\n",
        "\n",
        "theta_true = np.array([\n",
        "   0.39562, 890447238, 1.06870e-07,\n",
        "    75198,   0.00122, 1.59893e-09,\n",
        "    41905,\n",
        "     9381768, 24694962, 23810412, 61908988\n",
        "])\n",
        "\n",
        "lb_kin = np.array([0.35, 1.6e9, 0.8e-8, 8e4, 1e-3, 1e-9], float)\n",
        "ub_kin = np.array([0.38, 2.2e9, 2.7e-8, 1.4e5, 1.8e-1, 5.5e-9], float)\n",
        "y1min, y1max = 1e3, 5e8\n",
        "y2min, y2max = 1e1, 1e7\n",
        "lb_all = np.concatenate([lb_kin, [y2min], [y1min]*4])\n",
        "ub_all = np.concatenate([ub_kin, [y2max], [y1max]*4])\n",
        "bounds_list = list(zip(lb_all, ub_all))\n",
        "\n",
        "# -----------------------------\n",
        "# Generate noisy data\n",
        "# -----------------------------\n",
        "CV, SigmaFloor = 0.025, 1e5\n",
        "exp_data, sigma_data = [], []\n",
        "params_true = theta_true[:6]\n",
        "y2_true = theta_true[6]\n",
        "y1_trues = theta_true[7:]\n",
        "\n",
        "for i, y10 in enumerate(y1_trues):\n",
        "    clean = solve_dataset(t_obs[i], params_true, y10, y2_true, \"BDF\")\n",
        "    sigma_vals = np.maximum(CV * clean, SigmaFloor)\n",
        "    noisy = clean + np.random.normal(0, sigma_vals)\n",
        "    exp_data.append(noisy)\n",
        "    sigma_data.append(sigma_vals)\n",
        "\n",
        "print(\"Synthetic noisy data generated.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Log-likelihood\n",
        "# -----------------------------\n",
        "def loglikelihood(theta, method=\"BDF\"):\n",
        "    a_params = theta[:6]\n",
        "    y20 = theta[6]\n",
        "    y10s = theta[7:]\n",
        "    ll_total = 0.0\n",
        "    for i in range(4):\n",
        "        pred = solve_dataset(t_obs[i], a_params, y10s[i], y20, method, rtol=1e-6, atol=1e-8)\n",
        "        resid = exp_data[i] - pred\n",
        "        sigmas = sigma_data[i]\n",
        "        ll_total += np.sum(norm.logpdf(resid, loc=0, scale=sigmas))\n",
        "    return ll_total\n",
        "\n",
        "def neg_ll(theta):\n",
        "    return -loglikelihood(theta, method=\"BDF\")\n",
        "\n",
        "# -----------------------------\n",
        "# Compute MLE with global + local search\n",
        "# -----------------------------\n",
        "print(\"Running global optimization (this may take time)...\")\n",
        "res_global = differential_evolution(neg_ll, bounds_list, maxiter=50, polish=False, workers=-1)\n",
        "print(\"Global search done. Refining with local search...\")\n",
        "res_local = minimize(neg_ll, res_global.x, bounds=bounds_list,\n",
        "                     method=\"L-BFGS-B\", options={\"maxiter\":500, \"ftol\":1e-8})\n",
        "theta_mle = res_local.x\n",
        "print(\"Optimization success:\", res_local.success)\n",
        "print(\"MLE parameters:\", theta_mle)\n",
        "\n",
        "# -----------------------------\n",
        "# Profile likelihood with warm starts\n",
        "# -----------------------------\n",
        "def profile_likelihood(param_index, theta_mle, bounds, method=\"BDF\", n_grid=20):\n",
        "    p_grid = np.linspace(bounds[param_index][0], bounds[param_index][1], n_grid)\n",
        "    ll_values = np.empty_like(p_grid)\n",
        "    ll_mle = loglikelihood(theta_mle, method)\n",
        "\n",
        "    # Initial guess for nuisance = from MLE\n",
        "    nuisance_guess = [theta_mle[i] for i in range(len(theta_mle)) if i != param_index]\n",
        "\n",
        "    for j, val in enumerate(tqdm(p_grid, desc=f\"Param {param_index+1}\")):\n",
        "        theta_fixed = theta_mle.copy()\n",
        "        theta_fixed[param_index] = val\n",
        "        free_idx = [i for i in range(len(theta_mle)) if i != param_index]\n",
        "        free_bounds = [bounds[i] for i in free_idx]\n",
        "\n",
        "        def neg_ll_nuisance(free_params):\n",
        "            theta_var = theta_fixed.copy()\n",
        "            theta_var[free_idx] = free_params\n",
        "            return -loglikelihood(theta_var, method)\n",
        "\n",
        "        res = minimize(neg_ll_nuisance, nuisance_guess, bounds=free_bounds,\n",
        "                       method=\"L-BFGS-B\", options={\"ftol\":1e-8, \"gtol\":1e-8, \"maxiter\":200})\n",
        "        ll_values[j] = -res.fun\n",
        "        nuisance_guess = res.x  # warm start for next step\n",
        "\n",
        "    norm_ll = ll_values - ll_mle\n",
        "    return param_index, p_grid, norm_ll\n",
        "\n",
        "# -----------------------------\n",
        "# Run all profiles in parallel\n",
        "# -----------------------------\n",
        "results = Parallel(n_jobs=8)(\n",
        "    delayed(profile_likelihood)(i, theta_mle, bounds_list, \"BDF\", n_grid=15)\n",
        "    for i in range(6)\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Plot all results\n",
        "# -----------------------------\n",
        "param_labels = [r\"$c_1$\", r\"$c_{\\max}$\", r\"$\\phi_e$\", r\"$\\gamma_e$\", r\"$\\delta_e$\", r\"$\\eta_e$\"]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15,8))\n",
        "axes = axes.ravel()\n",
        "cutoff = -chi2.ppf(0.95, df=1)/2\n",
        "\n",
        "for param_index, p_grid, norm_ll in results:\n",
        "    ax = axes[param_index]\n",
        "    ax.plot(p_grid, norm_ll, color='blue', lw=2, label=\"Profile\")\n",
        "    ax.plot(p_grid, norm_ll, 'ro', markeredgecolor='black', label=\"Steps\")\n",
        "    ax.axhline(cutoff, color='green', linestyle='--', label='95% CI cutoff')\n",
        "    ax.axvline(theta_mle[param_index], color='black', linestyle=':', label='MLE')\n",
        "    ax.set_xlabel(param_labels[param_index])\n",
        "    ax.set_ylabel(r\"$\\Delta$ log-likelihood\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}